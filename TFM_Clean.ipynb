{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from gymnasium import Env\n",
    "from gymnasium.spaces import Box\n",
    "import copy\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [],
   "source": [
    "class Architecture:\n",
    "    def __init__(self):\n",
    "        self.space_flag = 0\n",
    "        self.c_capacity, self.s_capacity = 1000, 100                                         # Capacity of the devices\n",
    "        # self.a1, self.a2, self.a3, self.mc = 0.000125, 0.000010, 0.000200, 0.001           # Weight of every type of data\n",
    "        self.weights = [0.0125, 0.0010, 0.0200, 0.1000]                                      # a1, a2, a3, mc\n",
    "        self.lifetime = {'a1': 10000, 'a2': 20000, 'a3': 10000, 'mc': 1000}                  # Max lifetime of the different data types\n",
    "        self.total_c = 2\n",
    "        self.total_s = 6\n",
    "        self.max_actions = 20\n",
    "\n",
    "        self.devices = {}\n",
    "        self.data = {\n",
    "            'a1': {},\n",
    "            'a2': {},\n",
    "            'a3': {},\n",
    "            'mc': {},\n",
    "        }\n",
    "        self.latencies = {}\n",
    "\n",
    "        for i in range(self.total_c):\n",
    "            for j in (self.data.keys()):\n",
    "                self.data[j]['c'+str(i)] = 0\n",
    "            self.devices['c'+str(i)] = {'a1': 0, 'a2': 0, 'a3': 0, 'mc': 0}\n",
    "            self.latencies['c'+str(i)] = {}\n",
    "        for i in range(self.total_s):\n",
    "            for j in (self.data.keys()):\n",
    "                self.data[j]['s'+str(i)] = 0\n",
    "            self.devices['s'+str(i)] = {'a1': 0, 'a2': 0, 'a3': 0, 'mc': 0}\n",
    "            self.latencies['s'+str(i)] = {}\n",
    "\n",
    "        for i in self.latencies.keys():\n",
    "            for j in self.latencies.keys():\n",
    "                self.latencies[i][j] = 0\n",
    "\n",
    "        self.data_types = []\n",
    "        self.data_allocation = []\n",
    "        self.data_times = []\n",
    "\n",
    "        self.data_allocation_dict = []\n",
    "\n",
    "        self.action_type = []\n",
    "        self.action_device = []\n",
    "\n",
    "        randomized = list(self.devices.keys())\n",
    "        random.shuffle(randomized)\n",
    "\n",
    "        bound = round(len(self.devices)/4)\n",
    "\n",
    "        self.clusters = {\n",
    "            'a1': randomized[:bound],\n",
    "            'a2': randomized[bound:bound*2],\n",
    "            'a3': randomized[bound*2:bound*3],\n",
    "            'mc': randomized[bound*3:]\n",
    "        }\n",
    "\n",
    "        self.visualization()\n",
    "\n",
    "    def to_int(self, device):\n",
    "        return list(self.devices.keys()).index(device)\n",
    "\n",
    "    def to_device(self, position):\n",
    "        return list(self.devices.keys())[position]\n",
    "\n",
    "    def construct_dictionaries(self):\n",
    "        for i in self.data:\n",
    "            for j in self.data[i]:\n",
    "                self.data[i][j] = 0\n",
    "        for i in self.devices:\n",
    "            for j in self.devices[i]:\n",
    "                self.devices[i][j] = 0\n",
    "        for device, d_type in zip(self.data_allocation_dict,self.data_types):\n",
    "            self.data[d_type][device] += 1\n",
    "            self.devices[device][d_type] += 1\n",
    "\n",
    "    def update(self, data_type, device):\n",
    "        self.data_types.append(data_type)\n",
    "        self.data_allocation_dict.append(device)\n",
    "        self.data_allocation.append(self.to_int(device))\n",
    "        self.data_times.append(0)\n",
    "        self.devices[device][data_type] += 1\n",
    "        self.data[data_type][device] += 1\n",
    "\n",
    "    def heart_beat(self):\n",
    "        deads = []\n",
    "        for i in range(len(self.data_times)):\n",
    "            self.data_times[i] += 1\n",
    "            if self.data_times[i] == self.lifetime[self.data_types[i]]:\n",
    "                deads.append(i)\n",
    "\n",
    "        removed = 0\n",
    "        for i in deads:\n",
    "            self.devices[self.data_allocation_dict[i-removed]][self.data_types[i-removed]] -= 1\n",
    "            self.data[self.data_types[i-removed]][self.data_allocation_dict[i-removed]] -= 1\n",
    "            self.data_types.pop(i - removed)\n",
    "            self.data_allocation_dict.pop(i - removed)\n",
    "            self.data_allocation.pop(i - removed)\n",
    "            self.data_times.pop(i - removed)\n",
    "            removed += 1\n",
    "\n",
    "    def free_space(self):\n",
    "        load = {}\n",
    "        for i in self.devices.keys():\n",
    "            if list(i)[0] == 'c':\n",
    "                load[i] = (self.c_capacity - sum([a*b for a,b in zip(list(self.devices[i].values()), self.weights)]))/self.c_capacity\n",
    "            else:\n",
    "                load[i] = (self.s_capacity - sum([a*b for a,b in zip(list(self.devices[i].values()), self.weights)]))/self.s_capacity\n",
    "            if load[i] <= 0.2:\n",
    "                self.space_flag = i\n",
    "        return load\n",
    "\n",
    "    def visualization(self):\n",
    "        keys = list(self.devices.keys())\n",
    "        cs = keys[:self.total_c]\n",
    "        ss = keys[self.total_c:]\n",
    "\n",
    "        colors = []\n",
    "        sizes = []\n",
    "\n",
    "        graph = nx.Graph()\n",
    "\n",
    "        colors.append('lightblue')\n",
    "        sizes.append(1000)\n",
    "        index = 0\n",
    "        for i in range(len(cs)):\n",
    "            if i != len(cs)-1:\n",
    "                colors.append('lightblue')\n",
    "                sizes.append(1000)\n",
    "                graph.add_edge(cs[i],cs[i+1])\n",
    "                graph.add_weighted_edges_from([(cs[i],cs[i+1],10)])\n",
    "                for j in range(int(len(ss)/self.total_c)):\n",
    "                    colors.append('orange')\n",
    "                    sizes.append(100)\n",
    "                    graph.add_edge(cs[i],ss[index])\n",
    "                    graph.add_weighted_edges_from([(cs[i],ss[index],4)])\n",
    "                    index += 1\n",
    "            else:\n",
    "                graph.add_edge(cs[i],cs[0])\n",
    "                graph.add_weighted_edges_from([(cs[i],cs[0],10)])\n",
    "                for j in range(int(len(ss)/self.total_c)+len(ss)%self.total_c):\n",
    "                    graph.add_edge(cs[i],ss[index])\n",
    "                    graph.add_weighted_edges_from([(cs[i],ss[index],4)])\n",
    "                    colors.append('orange')\n",
    "                    sizes.append(100)\n",
    "                    index += 1\n",
    "\n",
    "        pos = nx.spring_layout(graph)  # Position nodes using a spring layout algorithm\n",
    "        nx.draw(graph, pos, with_labels=True, node_size=sizes, node_color=colors, font_weight=12, font_color='black', edge_color='gray')\n",
    "        edge_labels = nx.get_edge_attributes(graph, 'weight')\n",
    "        nx.draw_networkx_edge_labels(graph, pos, edge_labels=edge_labels)\n",
    "\n",
    "        plt.title(\"Architecture:\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "        for u in graph.nodes:\n",
    "            shortest_paths = nx.shortest_path_length(graph, source=u, weight='weight')\n",
    "            for v, weight in shortest_paths.items():\n",
    "                self.latencies[u][v] = weight\n",
    "\n",
    "    def compute_total_latency(self):\n",
    "        total_latency = 0\n",
    "        for i in range(len(self.action_type)):\n",
    "            total_latency += sum([a*b for a,b in zip(self.data[self.action_type[i]].values(), self.latencies[self.action_device[i]].values())])\n",
    "        return total_latency\n",
    "\n",
    "    def generate(self, operation):\n",
    "        if operation == 'a1' or operation == 'a2' or operation == 'a3':\n",
    "            for i in self.devices.keys():\n",
    "                self.update(operation,i)\n",
    "        elif operation == 'mc':\n",
    "            for i in self.devices.keys():\n",
    "                if list(i)[0] == 's':\n",
    "                    self.update('mc',i)\n",
    "        elif operation.split('_')[0] == 'ai':\n",
    "            device=random.sample(list(self.clusters[operation.split('_')[1]]),1)\n",
    "            self.action_device.append(device[0])\n",
    "            self.action_type.append(operation.split('_')[1])\n",
    "            difference = len(self.action_device) - self.max_actions\n",
    "            if difference >= 0:\n",
    "                for i in range(difference):\n",
    "                    self.action_device.pop(0)\n",
    "                    self.action_type.pop(0)\n",
    "\n",
    "    def greedy_algorithm(self): # baseline?\n",
    "        if self.space_flag == 0:\n",
    "            allocation = []\n",
    "            allocation_dev = []\n",
    "            for i in self.data_types:\n",
    "                allocation.append(self.to_int(random.sample(list(self.clusters[i]),1)[0]))\n",
    "                allocation_dev.append(random.sample(list(self.clusters[i]),1)[0])\n",
    "            self.data_allocation = allocation\n",
    "            self.data_allocation_dict = allocation_dev\n",
    "            self.construct_dictionaries()\n",
    "            result = self.free_space()\n",
    "        else:\n",
    "            problematic_key = None\n",
    "            for key, value in self.clusters.items():\n",
    "                if self.space_flag in value:\n",
    "                    problematic_key = key\n",
    "                    break\n",
    "            self.clusters[problematic_key].extend(element for element in self.devices if element[0]==('c'))\n",
    "            self.space_flag = 0\n",
    "            result = self.greedy_algorithm()\n",
    "\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0, 3, 5, 7, 0], dtype=int16)"
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class SimulatedArchitecture(Env):\n",
    "    def __init__(self, architecture, num_devices):\n",
    "        self.arch = architecture\n",
    "        self.num_devices = num_devices\n",
    "        self.weights = arch.weights\n",
    "        self.free_space = list(arch.free_space().values())\n",
    "        self.reward = 0\n",
    "        self.executions = ['a1','a2','mc','a1','ai_a2','mc','a3','ai_a1','mc','a1','ai_a3','mc','a2','a3','ai_a2','mc','ai_a1','a1','mc','ai_a3','ai_mc']\n",
    "        self.len_executions = len(self.executions)\n",
    "        self.index = 0\n",
    "    def get_obs(self):\n",
    "        return {\"weights\": self.weights,\n",
    "                \"free_space\": self.free_space,\n",
    "                \"allocation\": self.allocation,\n",
    "                \"last_calls\": self.last_calls\n",
    "                }\n",
    "    def step(self, action):\n",
    "        latency = self.arch.compute_total_latency()\n",
    "        self.free_space = list(self.arch.free_space().values())\n",
    "        self.reward = 0\n",
    "\n",
    "        for i in self.free_space:\n",
    "            if i <= 0.2:\n",
    "                self.reward = -1\n",
    "                break\n",
    "\n",
    "        if self.reward != -1:\n",
    "            self.reward = 4000000*(1/(latency+1)) + 0.5*(1/(np.std(self.free_space)+0.00001))              # With those weights, the scale of both latency and std is the same for high values while the latency is the only one taken into account in initial states (when there is plenty of space in the system and distribution is not that important)\n",
    "        info = {}\n",
    "        done = True\n",
    "\n",
    "        return self.get_obs(), self.reward, done, info\n",
    "\n",
    "    def render(self):\n",
    "        pass\n",
    "    def reset(self):\n",
    "        if self.reward != -1:\n",
    "            self.arch.generate(self.executions[self.index])\n",
    "            self.arch.heart_beat()\n",
    "            self.index = self.index + 1 if self.index < self.len_executions-1 else 0\n",
    "        self.allocation = [self.arch.data_types,self.arch.data_allocation]\n",
    "        self.last_calls = [self.arch.action_type,self.arch.action_device]\n",
    "        self.action_space = Box(low=0, high=self.num_devices-1, shape=(len(self.allocation[1]),), dtype=np.int16)\n",
    "    def close(self):\n",
    "        pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "file_path = 'TFM/offline_dataset.json'\n",
    "\n",
    "with open(file_path) as json_file:\n",
    "    offline_dataset = json.load(json_file)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
